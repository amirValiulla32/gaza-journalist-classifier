{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaza Video Classifier - Colab Tutorial\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to set up a Python environment in Colab\n",
    "- How to install and run Ollama + LLaVA\n",
    "- How to upload files and run your scripts\n",
    "- How to download results\n",
    "\n",
    "**Runtime:** Click `Runtime` ‚Üí `Change runtime type` ‚Üí Select `T4 GPU` (or A100 if you have Google One)\n",
    "\n",
    "---\n",
    "\n",
    "## Understanding Cells\n",
    "\n",
    "- **‚ñ∂Ô∏è Play button**: Runs the cell\n",
    "- **Green checkmark**: Cell finished successfully  \n",
    "- **Red X**: Cell had an error\n",
    "- **Spinning circle**: Cell is still running\n",
    "\n",
    "**Run cells in order from top to bottom the first time!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 1: System Setup (Run Once Per Session)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1: Install System Dependencies\n",
    "\n",
    "This installs:\n",
    "- `ffmpeg`: Extract audio from videos\n",
    "- `tesseract-ocr`: Read text from images  \n",
    "- `tesseract-ocr-ara`: Arabic language support\n",
    "\n",
    "**Time:** ~30 seconds\n",
    "\n",
    "**What to expect:** Lots of text output, then \"‚úÖ System tools installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Update package list\n",
    "apt-get update -qq\n",
    "\n",
    "# Install video and OCR tools\n",
    "apt-get install -y -qq ffmpeg tesseract-ocr tesseract-ocr-ara tesseract-ocr-eng > /dev/null 2>&1\n",
    "\n",
    "echo \"‚úÖ System tools installed\"\n",
    "echo \"   - ffmpeg: $(ffmpeg -version | head -n1)\"\n",
    "echo \"   - tesseract: $(tesseract --version | head -n1)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2: Install Python Packages\n",
    "\n",
    "This installs:\n",
    "- `pytesseract`: Python wrapper for OCR\n",
    "- `pillow`: Image processing\n",
    "- `requests`: HTTP requests for Ollama API\n",
    "\n",
    "**Time:** ~10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytesseract pillow requests\n",
    "\n",
    "print(\"‚úÖ Python packages installed\")\n",
    "import pytesseract\n",
    "import PIL\n",
    "import requests\n",
    "print(f\"   - pytesseract: {pytesseract.__version__ if hasattr(pytesseract, '__version__') else 'installed'}\")\n",
    "print(f\"   - pillow: {PIL.__version__}\")\n",
    "print(f\"   - requests: {requests.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3: Install Whisper.cpp\n",
    "\n",
    "This:\n",
    "- Clones whisper.cpp from GitHub\n",
    "- Compiles it (builds the C++ code)\n",
    "- Downloads the multilingual model\n",
    "\n",
    "**Time:** ~2 minutes (compiling takes time)\n",
    "\n",
    "**Note:** You'll see compilation output - that's normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Clone whisper.cpp\n",
    "if [ ! -d \"whisper.cpp\" ]; then\n",
    "    git clone https://github.com/ggerganov/whisper.cpp.git\n",
    "    echo \"üì• Cloned whisper.cpp\"\n",
    "else\n",
    "    echo \"‚úÖ whisper.cpp already exists\"\n",
    "fi\n",
    "\n",
    "# Build it\n",
    "cd whisper.cpp\n",
    "make -j > /dev/null 2>&1\n",
    "echo \"üî® Built whisper.cpp\"\n",
    "\n",
    "# Download model if not already downloaded\n",
    "if [ ! -f \"models/ggml-base.bin\" ]; then\n",
    "    bash ./models/download-ggml-model.sh base\n",
    "    echo \"üì• Downloaded multilingual model\"\n",
    "else\n",
    "    echo \"‚úÖ Model already exists\"\n",
    "fi\n",
    "\n",
    "echo \"‚úÖ Whisper.cpp ready\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 4: Install Ollama\n",
    "\n",
    "Ollama is the server that runs LLaVA and DeepSeek locally.\n",
    "\n",
    "**Time:** ~30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "print(\"‚úÖ Ollama installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 5: Start Ollama Server\n",
    "\n",
    "This starts Ollama in the background so we can call it via API.\n",
    "\n",
    "**Important:** This cell needs to keep running! Don't stop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start Ollama server in background\n",
    "ollama_process = subprocess.Popen(\n",
    "    ['ollama', 'serve'],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL\n",
    ")\n",
    "\n",
    "# Wait for server to start\n",
    "print(\"üöÄ Starting Ollama server...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Test if it's running\n",
    "import requests\n",
    "try:\n",
    "    response = requests.get('http://localhost:11434/api/tags')\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Ollama server running\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Ollama might not be ready yet, wait a moment\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Ollama not responding, try running this cell again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 6: Download AI Models\n",
    "\n",
    "This downloads:\n",
    "- `llava:7b` - Vision model for analyzing frames\n",
    "- `llama2:13b` - Text model for classification (we'll use this instead of DeepSeek since DeepSeek might not be available)\n",
    "\n",
    "**Time:** ~5-10 minutes (downloading 4-5 GB total)\n",
    "\n",
    "**Note:** This is the longest step, but you only do it once per session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download LLaVA for vision\n",
    "print(\"üì• Downloading LLaVA (vision model)...\")\n",
    "!ollama pull llava:7b\n",
    "\n",
    "print(\"\\nüì• Downloading Llama2 (classification model)...\")\n",
    "!ollama pull llama2:13b\n",
    "\n",
    "print(\"\\n‚úÖ All models downloaded!\")\n",
    "print(\"\\nAvailable models:\")\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 2: Upload Your Code\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 7: Upload Python Scripts\n",
    "\n",
    "Upload these 3 files from your Mac:\n",
    "1. `analyze_frame_content.py`\n",
    "2. `extract_text_from_video.py`\n",
    "3. `classify_video_multimodal.py`\n",
    "\n",
    "**How to upload:**\n",
    "1. Run this cell\n",
    "2. Click \"Choose Files\" button that appears\n",
    "3. Select all 3 Python files\n",
    "4. Wait for upload to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Upload your 3 Python scripts:\")\n",
    "print(\"   - analyze_frame_content.py\")\n",
    "print(\"   - extract_text_from_video.py\")\n",
    "print(\"   - classify_video_multimodal.py\")\n",
    "print(\"\\nClick 'Choose Files' below and select all 3 files:\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"\\n‚úÖ Uploaded {len(uploaded)} files:\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"   - {filename} ({len(uploaded[filename])} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 8: Update Model Name in Scripts\n",
    "\n",
    "**Why:** Your scripts use `deepseek-v3.1:671b-cloud` but Colab uses `llama2:13b`\n",
    "\n",
    "This cell automatically fixes that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read classify_video_multimodal.py and update the model name\n",
    "import re\n",
    "\n",
    "# Update classify_video_multimodal.py\n",
    "with open('classify_video_multimodal.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Replace DeepSeek model with Llama2\n",
    "content = content.replace(\n",
    "    'from classify_video import extract_audio, transcribe_audio, LOCAL_LLM_MODEL',\n",
    "    'from classify_video import extract_audio, transcribe_audio\\nLOCAL_LLM_MODEL = \"llama2:13b\"'\n",
    ")\n",
    "\n",
    "with open('classify_video_multimodal.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"‚úÖ Updated model name to llama2:13b\")\n",
    "print(\"   (Scripts now use Colab-compatible model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 3: Process Videos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 9: Upload Video to Classify\n",
    "\n",
    "Upload a video file (mp4, avi, mov, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Upload a video file to classify:\")\n",
    "uploaded_video = files.upload()\n",
    "\n",
    "video_filename = list(uploaded_video.keys())[0]\n",
    "print(f\"\\n‚úÖ Video uploaded: {video_filename}\")\n",
    "print(f\"   Size: {len(uploaded_video[video_filename]) / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 10: Run Classification with Vision\n",
    "\n",
    "This runs the full multimodal pipeline:\n",
    "1. Extract audio\n",
    "2. Transcribe with Whisper\n",
    "3. Extract 15 frames\n",
    "4. OCR text from frames\n",
    "5. Vision analysis with LLaVA\n",
    "6. Classify with Llama2\n",
    "\n",
    "**Time:** ~30-60 seconds per video (much faster than your Mac!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the uploaded video filename\n",
    "video_file = video_filename\n",
    "\n",
    "print(f\"üé¨ Processing: {video_file}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run classification\n",
    "!python3 classify_video_multimodal.py \"{video_file}\" --language ar --frames 15 --strategy sections\n",
    "\n",
    "print(\"\\n‚úÖ Classification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 11: View Results\n",
    "\n",
    "Display the classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Find the result file\n",
    "result_files = [f for f in os.listdir('.') if f.endswith('_multimodal.json')]\n",
    "\n",
    "if result_files:\n",
    "    result_file = result_files[0]\n",
    "    \n",
    "    with open(result_file, 'r', encoding='utf-8') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CLASSIFICATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nüìÅ Video: {result['video_name']}\")\n",
    "    print(f\"üìÇ Category: {result['category']}\")\n",
    "    print(f\"üè∑Ô∏è  Tags: {', '.join(result['tags'])}\")\n",
    "    print(f\"üìä Confidence: {result['confidence']}\")\n",
    "    print(f\"\\nüí≠ Reasoning:\\n{result['reasoning']}\")\n",
    "    \n",
    "    if result.get('visual_evidence'):\n",
    "        print(f\"\\nüëÅÔ∏è  Visual Evidence:\")\n",
    "        for evidence in result['visual_evidence']:\n",
    "            print(f\"   - {evidence}\")\n",
    "    \n",
    "    print(f\"\\nüìà Processing Stats:\")\n",
    "    print(f\"   Audio: {result['transcript_length']} chars\")\n",
    "    print(f\"   OCR: {result['ocr_length']} chars\")\n",
    "    print(f\"   Vision: {result['vision_length']} chars ({result['num_frames_analyzed']} frames)\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"‚ùå No result file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 12: Download Results\n",
    "\n",
    "Download the JSON file with full classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Find and download result file\n",
    "result_files = [f for f in os.listdir('.') if f.endswith('_multimodal.json')]\n",
    "\n",
    "if result_files:\n",
    "    result_file = result_files[0]\n",
    "    print(f\"üì• Downloading: {result_file}\")\n",
    "    files.download(result_file)\n",
    "    print(\"‚úÖ Downloaded! Check your Mac's Downloads folder\")\n",
    "else:\n",
    "    print(\"‚ùå No result file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BONUS: Batch Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 13: Process Multiple Videos\n",
    "\n",
    "Upload and process 5-10 videos at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"üì§ Upload multiple videos (5-10 recommended):\")\n",
    "uploaded_batch = files.upload()\n",
    "\n",
    "video_files = [f for f in uploaded_batch.keys() if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "print(f\"\\n‚úÖ Uploaded {len(video_files)} videos\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, video_file in enumerate(video_files, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing {i}/{len(video_files)}: {video_file}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Run classification\n",
    "    !python3 classify_video_multimodal.py \"{video_file}\" --language ar --frames 15 --strategy sections\n",
    "    \n",
    "    # Load result\n",
    "    result_file = video_file.rsplit('.', 1)[0] + '_multimodal.json'\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r', encoding='utf-8') as f:\n",
    "            results.append(json.load(f))\n",
    "        print(f\"‚úÖ {video_file} classified\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {video_file} - no result file\")\n",
    "\n",
    "# Save combined results\n",
    "with open('batch_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Batch processing complete!\")\n",
    "print(f\"   Processed: {len(results)}/{len(video_files)} videos\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Download batch results\n",
    "print(\"üì• Downloading batch results...\")\n",
    "files.download('batch_results.json')\n",
    "print(\"‚úÖ Done! Check your Downloads folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tips & Troubleshooting\n",
    "---\n",
    "\n",
    "### Session Management\n",
    "- **Session timeout**: ~90 minutes idle (Google One: longer)\n",
    "- **Keep alive**: Interact with the page occasionally\n",
    "- **Download results**: Always download before closing!\n",
    "\n",
    "### If Something Breaks\n",
    "- **Ollama not responding**: Re-run Cell 5 (start server)\n",
    "- **Model not found**: Re-run Cell 6 (download models)\n",
    "- **Import error**: Re-run Cell 7 (upload scripts)\n",
    "\n",
    "### Performance\n",
    "- **With Google One**: A100 GPU = ~30-60s per video\n",
    "- **Free tier**: T4 GPU = ~60-90s per video\n",
    "- **Batch processing**: ~50 videos per hour\n",
    "\n",
    "### Next Session\n",
    "When you open this notebook again:\n",
    "1. Run Cells 1-6 (setup) - takes ~10 min\n",
    "2. Run Cell 7 (upload scripts) - takes ~10 sec  \n",
    "3. Then jump to Cell 9 (process videos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
