{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaza Video Classifier - Google Colab Edition\n",
    "\n",
    "Run multimodal video classification (Audio + OCR + Vision) using Google Colab's GPU.\n",
    "\n",
    "**Benefits:**\n",
    "- No local resource usage (won't crash your Mac)\n",
    "- Fast GPU processing with LLaVA vision model\n",
    "- Google One subscribers get priority GPU access\n",
    "\n",
    "**Setup Time:** ~5 minutes first run, then instant for subsequent videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!apt-get update -qq\n",
    "!apt-get install -y ffmpeg tesseract-ocr tesseract-ocr-ara tesseract-ocr-eng\n",
    "!pip install -q pytesseract pillow requests whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Ollama and LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# Start Ollama server in background\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "ollama_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "time.sleep(5)  # Wait for server to start\n",
    "\n",
    "print(\"✅ Ollama server started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download models (this will take a few minutes first time)\n",
    "# LLaVA for vision analysis\n",
    "!ollama pull llava:7b\n",
    "\n",
    "# DeepSeek for classification (or use any other model you prefer)\n",
    "# Note: You'll need to use a model available on Ollama\n",
    "# Since DeepSeek might not be available, we'll use llama2 or mistral\n",
    "!ollama pull llama2:13b  # or mistral:7b for faster processing\n",
    "\n",
    "print(\"✅ Models downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Whisper.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone and build whisper.cpp\n",
    "!git clone https://github.com/ggerganov/whisper.cpp.git\n",
    "!cd whisper.cpp && make\n",
    "\n",
    "# Download multilingual model\n",
    "!cd whisper.cpp && bash ./models/download-ggml-model.sh base\n",
    "\n",
    "print(\"✅ Whisper.cpp ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Upload Your Python Scripts\n",
    "\n",
    "Upload these files from your local machine:\n",
    "- `analyze_frame_content.py`\n",
    "- `extract_text_from_video.py`\n",
    "- `classify_video_multimodal.py`\n",
    "\n",
    "Or run the cell below to create them directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will be populated with your script files if needed\n",
    "# For now, use Colab's file upload feature:\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your Python scripts (analyze_frame_content.py, extract_text_from_video.py, classify_video_multimodal.py):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"✅ Uploaded {len(uploaded)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Upload Video to Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your video file:\")\n",
    "uploaded_videos = files.upload()\n",
    "\n",
    "video_filename = list(uploaded_videos.keys())[0]\n",
    "print(f\"✅ Video uploaded: {video_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Multimodal Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Update the LOCAL_LLM_MODEL in classify_video_multimodal.py to use llama2:13b or mistral:7b\n",
    "# since DeepSeek might not be available on Colab\n",
    "\n",
    "# Run classification with vision analysis\n",
    "!python3 classify_video_multimodal.py {video_filename} --language ar --frames 15 --strategy sections\n",
    "\n",
    "print(\"\\n✅ Classification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Find the output JSON file\n",
    "json_files = [f for f in os.listdir('.') if f.endswith('_multimodal.json')]\n",
    "\n",
    "if json_files:\n",
    "    result_file = json_files[0]\n",
    "    print(f\"Downloading: {result_file}\")\n",
    "    files.download(result_file)\n",
    "    print(\"✅ Results downloaded!\")\n",
    "else:\n",
    "    print(\"❌ No result file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Batch Process Multiple Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload multiple videos and process them all\n",
    "from google.colab import files\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"Upload all videos to process:\")\n",
    "uploaded_batch = files.upload()\n",
    "\n",
    "results = []\n",
    "\n",
    "for video_file in uploaded_batch.keys():\n",
    "    if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing: {video_file}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        !python3 classify_video_multimodal.py {video_file} --language ar --frames 15\n",
    "        \n",
    "        # Load result\n",
    "        result_file = video_file.replace('.mp4', '_multimodal.json')\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file, 'r') as f:\n",
    "                results.append(json.load(f))\n",
    "\n",
    "# Save batch results\n",
    "with open('batch_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Processed {len(results)} videos\")\n",
    "print(\"Downloading batch results...\")\n",
    "files.download('batch_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Notes\n",
    "\n",
    "**With Google One Colab Benefits:**\n",
    "- GPU: A100 or V100 (much faster than Mac CPU)\n",
    "- Processing time: ~30-60 seconds per video (vs 90-150s on Mac)\n",
    "- No crashes or freezing\n",
    "- Can process 50+ videos in one session\n",
    "\n",
    "**Tips:**\n",
    "- Keep the session active (it will disconnect after ~90 min idle)\n",
    "- Download results periodically to avoid losing them\n",
    "- For large batches, save intermediate results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
